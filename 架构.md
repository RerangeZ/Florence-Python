这其实是一个歌声合成引擎。参照原来的代码（已经经过技术验证），改变架构。

新的架构如下。

## 元素（数据类）

**time** word的一个属性。

start ：相对乐句开始为0 基准。音符开始的时间点，单位为ms

end: 相对乐句开始为0 基准。音符结束的时间点，单位为ms

最小单位：**word**，来自musicXML中的音符，包含以下属性

- pich 音高频率（Hz）
- time 结构体，如上
- lrc 歌词拼音，若musicXML输入的为中文则转成拼音，忽略声调
- oriWave FlorenceSpeakGenerateor合成的原始tts二进制数据

**section** 乐段，包含以下属性

- wordList 包含本乐段所有word的列表。在创建时应检查音符没有重叠。
- sectionStart 本乐段开始时间，0基准为歌曲开头，单位ms
- sectionSrc 链接oriWave合成的二进制数据

**track** 整个音轨

- sectionList 同wordList
- trackWaveData 一个numpy向量，储存着合成好的整个音轨音频

**song** 整个歌曲

- trackList 同wordList
- WaveData 一个numpy向量，储存着合成好的整个歌曲音频
- name 输入musicXML的文件名称



## 工具

这个软件采用类似于GCC的流水线架构。由以下几个组成。

FlorenceScoreDecoder 负责处理musicXML输入并解析为song对象（具体对象结构上文有描述）

FlorenceSpeakGenerateor 输入一个song对象，对里面的word对象处理，根据lrc合成oriWave

FlorenceCoder 输入一个song对象，负责调用world声码器，使得word中oriWave的基频与pich符合

FlorenceWaveConnecter 负责平滑链接oriWave到sectionSrc（请补全这个算法，原始项目没有）

FlorenceOutputGenerater 负责拼接section到track进而到song。注意，只是简单的依据时间叠加就行，不用像上一步那样平滑链接。并在最后输出{name}.wav,写入到output目录下。

FlorenceEngine0 负责调度以上几个工具构成的流水线,是整个工程的入口。

# 未提及的标准按照之前的来（如输入musicXML的游览初始目录未提及，就按原来的在input下，若原工程没有，则向我提出，一起探讨。）

